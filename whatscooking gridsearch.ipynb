{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import preprocessing, decomposition, svm, pipeline, metrics\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "train=pd.read_json('../input/train.json' )\n",
    "test=pd.read_json('../input/test.json')\n",
    "\n",
    "train['ingredients'] = [\", \".join(ingredients) for ingredients in train['ingredients']]\n",
    "test['ingredients']=[\", \".join(ingredients) for ingredients in test['ingredients']]\n",
    "\n",
    "#To find logloss\n",
    "def multiclass_logloss(actual, predicted, eps=1e-15):\n",
    "    \"\"\"Multi class version of Logarithmic Loss metric.\n",
    "    :param actual: Array containing the actual target classes\n",
    "    :param predicted: Matrix with class predictions, one probability per class\n",
    "    \"\"\"\n",
    "    # Convert 'actual' to a binary array if it's not already:\n",
    "    if len(actual.shape) == 1:\n",
    "        actual2 = np.zeros((actual.shape[0], predicted.shape[1]))\n",
    "        for i, val in enumerate(actual):\n",
    "            actual2[i, val] = 1\n",
    "        actual = actual2\n",
    "\n",
    "    clip = np.clip(predicted, eps, 1 - eps)\n",
    "    rows = actual.shape[0]\n",
    "    vsota = np.sum(actual * np.log(clip))\n",
    "    return -1.0 / rows * vsota\n",
    "\n",
    "\n",
    "#Use label encoders to convert text labels into integers\n",
    "\n",
    "lblencdr=preprocessing.LabelEncoder()\n",
    "y_cuisine=lblencdr.fit_transform(train['cuisine'].values)\n",
    "#stratify option in train_test_split will ensure that the data is taken in the same proportion as the original dataset. This is particularly helpful in unbalanced datasets\n",
    "X_train, X_val, y_train, y_val = train_test_split(train['ingredients'].values, y_cuisine, \n",
    "                                                  stratify=y_cuisine,\n",
    "                                                  test_size=0.1,\n",
    "                                                  shuffle=True,\n",
    "                                                  random_state=0)\n",
    "\n",
    "vect=TfidfVectorizer().fit(list(X_train)+list(X_val))\n",
    "X_train_vect=vect.transform(X_train)\n",
    "x_valid_vect=vect.transform(X_val)\n",
    "\n",
    "#Grid Search Technique. Create a scorer function by using make_scorer\n",
    "mll_scorer=metrics.make_scorer(multiclass_logloss, greater_is_better=False, needs_proba=True)\n",
    "\n",
    "#Create a pipeline\n",
    "svd=TruncatedSVD()\n",
    "\n",
    "#Initialize the standard scalar\n",
    "scl=preprocessing.StandardScaler()\n",
    "\n",
    "#logistic Regression\n",
    "lr=LogisticRegression()\n",
    "\n",
    "clf=pipeline.Pipeline([('svd', svd),\n",
    "                      ('scl', scl),\n",
    "                      ('lr', lr)]\n",
    "                     )\n",
    "\n",
    "#create a grid of parameters\n",
    "\n",
    "param_grid={'svd__n_components': [120, 180],\n",
    "            'lr__C': [0.1, 1.0, 10],\n",
    "             'lr__penalty': ['l1', 'l2']}\n",
    "\n",
    "model=GridSearchCV(estimator=clf, param_grid=param_grid, scoring=mll_scorer,\n",
    "                  verbose=10, n_jobs=-1, iid=True, refit=True, cv=2)\n",
    "\n",
    "model.fit(X_train_vect, y_train)\n",
    "\n",
    "print(\"Best score: %0.3f\" % model.best_score_)\n",
    "print(\"Best Parameters set:\")\n",
    "best_parameters=model.best_estimator_.get_params()\n",
    "\n",
    "for param_name in sorted(param_grid.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "predictions=model.predict(vect.transform(X_val))\n",
    "print(f1_score(predictions, y_val, average='micro'))\n",
    "y_predict=model.predict(vect.transform(test['ingredients']))\n",
    "\n",
    "test['cuisine']=lblencdr.inverse_transform(y_predict)\n",
    "test = test.sort_values('id' , ascending=True)\n",
    "\n",
    "test[['id' , 'cuisine' ]].to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
